{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAbJKYXX1YMn"
      },
      "outputs": [],
      "source": [
        "!pip install bertopic\n",
        "!pip install cudf-cu11 dask-cudf-cu11 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cugraph-cu11 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install --upgrade cupy-cuda11x -f https://pip.cupy.dev/aarch64"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from google.colab import files\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqueIDlUTULi",
        "outputId": "c5270652-395f-4878-e61b-71bf33f3a073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file manually\n",
        "uploaded = files.upload()\n",
        "\n",
        "df = pd.read_csv(\"Preprocessed_jobs.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "-2hgGxhG1aJD",
        "outputId": "05a4362f-a3c4-4f63-d8b2-177c66e47536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c37119dd-cdcb-416e-8bc5-08ef1bbecb48\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c37119dd-cdcb-416e-8bc5-08ef1bbecb48\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Preprocessed_jobs.csv to Preprocessed_jobs (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def standardize_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords and lemmatize\n",
        "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "    return \" \".join(cleaned_tokens)\n",
        "\n",
        "df_clean = df.copy()\n",
        "df_clean['Cleaned Job Description'] = df_clean['Cleaned Job Description'].apply(standardize_text)"
      ],
      "metadata": {
        "id": "sajVH3gURALQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting specific phrases\n",
        "def extract_specific_phrases(text_list, keywords, ngram_range=(1, 3), n_features=10000, n_top_phrases=50):\n",
        "    \"\"\"\n",
        "    Extract specific n-grams related to provided keywords using TF-IDF.\n",
        "    \"\"\"\n",
        "    # TF-IDF vectorizer focusing on n-grams\n",
        "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=n_features, stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform(text_list)\n",
        "    terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Filter terms containing any of the specified keywords\n",
        "    relevant_terms = [term for term in terms if any(keyword in term for keyword in keywords)]\n",
        "\n",
        "    # Calculate mean TF-IDF score per term and sort by relevance\n",
        "    scores = tfidf_matrix.mean(axis=0).tolist()[0]\n",
        "    term_scores = {term: scores[idx] for idx, term in enumerate(terms) if term in relevant_terms}\n",
        "    sorted_terms = sorted(term_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Extract top phrases\n",
        "    top_phrases = [term for term, _ in sorted_terms[:n_top_phrases]]\n",
        "    return top_phrases\n",
        "\n",
        "# Define original domain-relevant keywords for focus\n",
        "domain_keywords = [\"data science\", \"data analysis\", \"generative ai\", \"llm\", \"machine learning\", \"cloud\", \"engineering\", \"processing\", \"data visualization\", \"data optimization\"]\n",
        "\n",
        "# Extract refined phrases from job descriptions using the desired method\n",
        "clean_refined_phrases = extract_specific_phrases(\n",
        "    df_clean['Cleaned Job Description'].tolist(),\n",
        "    keywords=domain_keywords,\n",
        "    ngram_range=(1, 3),\n",
        "    n_top_phrases=100\n",
        ")\n",
        "\n",
        "# Display the refined results\n",
        "clean_refined_phrases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykLa_4OJSIQG",
        "outputId": "b4a8fd22-ab34-455d-e547-5e0a298e76a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['machine learning',\n",
              " 'engineering',\n",
              " 'generative ai',\n",
              " 'llm',\n",
              " 'data science',\n",
              " 'cloud',\n",
              " 'processing',\n",
              " 'language processing',\n",
              " 'natural language processing',\n",
              " 'data analysis',\n",
              " 'machine learning model',\n",
              " 'software engineering',\n",
              " 'model llm',\n",
              " 'language model llm',\n",
              " 'data engineering',\n",
              " 'engineering team',\n",
              " 'science engineering',\n",
              " 'machine learning engineer',\n",
              " 'data visualization',\n",
              " 'cloud platform',\n",
              " 'data processing',\n",
              " 'engineering related',\n",
              " 'computer engineering',\n",
              " 'ai machine learning',\n",
              " 'generative ai solution',\n",
              " 'language processing nlp',\n",
              " 'processing nlp',\n",
              " 'computer science engineering',\n",
              " 'generative ai model',\n",
              " 'machine learning algorithm',\n",
              " 'electrical engineering',\n",
              " 'prompt engineering',\n",
              " 'experience machine learning',\n",
              " 'cloud computing',\n",
              " 'experience generative ai',\n",
              " 'generative ai technology',\n",
              " 'machine learning deep',\n",
              " 'engineering related field',\n",
              " 'engineering computer',\n",
              " 'engineering experience',\n",
              " 'preprocessing',\n",
              " 'science computer engineering',\n",
              " 'cloudbased',\n",
              " 'machine learning technique',\n",
              " 'machine learning ml',\n",
              " 'experience cloud',\n",
              " 'llm generative',\n",
              " 'llm generative ai',\n",
              " 'google cloud',\n",
              " 'science data science',\n",
              " 'engineering computer science',\n",
              " 'intelligence machine learning',\n",
              " 'cloud service',\n",
              " 'generative ai application',\n",
              " 'engineering data',\n",
              " 'data science related',\n",
              " 'engineering relevant',\n",
              " 'machine learning ai',\n",
              " 'data science team',\n",
              " 'engineering mathematics',\n",
              " 'product engineering',\n",
              " 'machine learning data',\n",
              " 'engineering product',\n",
              " 'engineering best',\n",
              " 'engineering best practice',\n",
              " 'science engineering related',\n",
              " 'science machine learning',\n",
              " 'processing computer',\n",
              " 'machine learning framework',\n",
              " 'computer engineering relevant',\n",
              " 'engineering relevant technical',\n",
              " 'data science solution',\n",
              " 'science electrical engineering',\n",
              " 'engineering data science',\n",
              " 'llm research',\n",
              " 'exploratory data analysis',\n",
              " 'llm multimodal',\n",
              " 'learning generative ai',\n",
              " 'understanding machine learning',\n",
              " 'cloud environment',\n",
              " 'ai llm',\n",
              " 'processing computer vision',\n",
              " 'processing nlp computer',\n",
              " 'machine learning computer',\n",
              " 'adopted cloud',\n",
              " 'adopted cloud platform',\n",
              " 'broadly adopted cloud',\n",
              " 'cloud computing stopped',\n",
              " 'cloud platform pioneered',\n",
              " 'pioneered cloud',\n",
              " 'pioneered cloud computing',\n",
              " 'platform pioneered cloud',\n",
              " 'machine learning research',\n",
              " 'data science machine',\n",
              " 'advanced machine learning',\n",
              " 'machine learning related',\n",
              " 'knowledge machine learning',\n",
              " 'data machine learning',\n",
              " 'language processing computer',\n",
              " 'data visualization tool']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference set for analysing\n",
        "reference_set = {\n",
        "    \"Programming\": [\n",
        "        \"Python\", \"R\", \"SQL\", \"Java\", \"C++\", \"JavaScript\", \"C#\", \"MATLAB\",\n",
        "        \"Perl\", \"Ruby\", \"Go\", \"Scala\", \"Swift\", \"HTML\", \"CSS\", \"Dart\",\n",
        "        \"Kotlin\", \"Shell Scripting\", \"Rust\", \"TypeScript\", \"Bash\", \"Fortran\",\n",
        "        \"Lua\", \"VBScript\", \"Julia\", \"Assembly\", \"F#\", \"Delphi\", \"Objective-C\",\n",
        "        \"COBOL\"\n",
        "    ],\n",
        "    \"Mathematics & Statistics\": [\n",
        "        \"Probability\", \"Linear Algebra\", \"Hypothesis Testing\",\n",
        "        \"Descriptive Analytics\", \"Statistical Modeling\", \"Bayesian Statistics\",\n",
        "        \"Monte Carlo Simulation\", \"Optimization Techniques\", \"Game Theory\",\n",
        "        \"Markov Chains\", \"Time Series Analysis\", \"Stochastic Processes\",\n",
        "        \"Cluster Analysis\", \"Principal Component Analysis (PCA)\",\n",
        "        \"Dimensionality Reduction\", \"Numerical Analysis\", \"Regression Analysis\",\n",
        "        \"Variance Analysis\", \"Matrix Decomposition\", \"Graph Theory\",\n",
        "        \"Probability Distributions\", \"Sampling Methods\", \"ANOVA\",\n",
        "        \"Non-parametric Statistics\", \"Factor Analysis\", \"Spatial Statistics\",\n",
        "        \"Quantitative Methods\", \"Predictive Models\", \"Statistical Inference\",\n",
        "        \"Mathematical Programming\"\n",
        "    ],\n",
        "    \"Machine Learning\": [\n",
        "        \"Logistic Regression\", \"Random Forests\", \"Neural Networks\",\n",
        "        \"Supervised Learning\", \"Unsupervised Learning\", \"Reinforcement Learning\",\n",
        "        \"Model Deployment\", \"Predictive Analytics\", \"Prescriptive Analytics\",\n",
        "        \"Support Vector Machines (SVM)\", \"Gradient Boosting\", \"XGBoost\",\n",
        "        \"CatBoost\", \"LightGBM\", \"K-Nearest Neighbors\", \"Clustering Techniques\",\n",
        "        \"AutoML\", \"Model Optimization\", \"Deep Reinforcement Learning\",\n",
        "        \"GANs (Generative Adversarial Networks)\", \"Transfer Learning\",\n",
        "        \"Hyperparameter Tuning\", \"Semi-supervised Learning\",\n",
        "        \"Anomaly Detection\", \"Online Learning\", \"Active Learning\",\n",
        "        \"Feature Selection\", \"Time Series Forecasting\", \"Bagging\",\n",
        "        \"Ensemble Methods\"\n",
        "    ],\n",
        "    \"Data Manipulation\": [\n",
        "        \"Data Cleaning\", \"Feature Engineering\", \"Data Wrangling\",\n",
        "        \"Data Integration\", \"Data Transformation\", \"Dimensionality Reduction\",\n",
        "        \"Data Sampling\", \"Data Normalization\", \"Data Imputation\",\n",
        "        \"Pivot Tables\", \"Data Merging\", \"Data Aggregation\", \"Outlier Detection\",\n",
        "        \"Reshaping Data\", \"Slicing and Indexing\", \"Handling Missing Data\",\n",
        "        \"Data Encoding\", \"One-Hot Encoding\", \"Binning\", \"Data Scaling\",\n",
        "        \"Data Partitioning\", \"ETL Processes\", \"Data Augmentation\",\n",
        "        \"Feature Scaling\", \"Cross Validation\", \"Data Reduction\",\n",
        "        \"Data Balancing\", \"Data Resampling\", \"Data Annotation\",\n",
        "        \"Data Schema Design\"\n",
        "    ],\n",
        "    \"Data Management\": [\n",
        "        \"Data Governance\", \"Metadata Management\", \"FAIR Data Principles\",\n",
        "        \"Data Provenance\", \"Data Warehousing\", \"Data Lakes\",\n",
        "        \"Data Curation\", \"Data Quality Assurance\", \"Data Stewardship\",\n",
        "        \"Master Data Management\", \"Data Lineage\", \"ETL Pipelines\",\n",
        "        \"Data Versioning\", \"Backup and Recovery\", \"Access Control\",\n",
        "        \"Data Partitioning\", \"Schema Evolution\", \"Distributed Databases\",\n",
        "        \"Data Archiving\", \"Data Replication\", \"Stream Processing\",\n",
        "        \"Data Security\", \"Data Auditing\", \"Data Masking\",\n",
        "        \"Data Sensitivity Management\", \"Data Dictionary\",\n",
        "        \"Hierarchical Databases\", \"Relational Databases\",\n",
        "        \"Object-Oriented Databases\", \"Graph Databases\"\n",
        "    ],\n",
        "    \"Generative AI\": [\n",
        "        \"Transformer Architectures\", \"Fine-tuning\", \"Prompt Engineering\",\n",
        "        \"Tokenization\", \"LLM Applications\", \"GPT Models\", \"BERT Models\",\n",
        "        \"Zero-Shot Learning\", \"Few-Shot Learning\", \"Masked Language Modeling\",\n",
        "        \"Seq2Seq Models\", \"Text-to-Image Generation\", \"GANs for Images\",\n",
        "        \"Diffusion Models\", \"Natural Language Generation\", \"Speech Synthesis\",\n",
        "        \"Image Captioning\", \"Audio Generation\", \"Pretrained Models\",\n",
        "        \"Text Summarization\", \"Knowledge Distillation\", \"Model Pruning\",\n",
        "        \"Language Understanding\", \"Data Augmentation for AI\",\n",
        "        \"Contrastive Learning\", \"Episodic Memory Models\", \"Autoregressive Models\",\n",
        "        \"Bidirectional Models\", \"Language Modeling\", \"Text Classification\",\n",
        "        \"Multimodal AI\"\n",
        "    ],\n",
        "    \"Visualization & Storytelling\": [\n",
        "        \"Data Visualization\", \"Dashboard Design\", \"Data Storytelling\",\n",
        "        \"Interactive Visualizations\", \"Heatmaps\", \"Choropleth Maps\",\n",
        "        \"Scatter Plots\", \"Bar Charts\", \"Line Charts\", \"Pie Charts\",\n",
        "        \"Treemaps\", \"Histograms\", \"Box Plots\", \"Waterfall Charts\",\n",
        "        \"Bubble Charts\", \"Word Clouds\", \"Network Graphs\", \"Geospatial Visuals\",\n",
        "        \"3D Visualizations\", \"Annotated Charts\", \"Drill-Down Visuals\",\n",
        "        \"Real-Time Dashboards\", \"Storyboarding\", \"Infographics\",\n",
        "        \"Time-Series Visualizations\", \"Cross-Filtering\", \"Multi-View Charts\",\n",
        "        \"Visual Encodings\", \"Interactive Dashboards\", \"Custom Visuals\"\n",
        "    ],\n",
        "    \"Ethics & Compliance\": [\n",
        "        \"Bias Mitigation\", \"Data Privacy\", \"Ethical AI\", \"GDPR Compliance\",\n",
        "        \"Responsible AI\", \"IPR Protection\", \"Algorithmic Fairness\",\n",
        "        \"Transparency in AI\", \"Explainable AI\", \"Adversarial Robustness\",\n",
        "        \"Cybersecurity\", \"Data Security\", \"Informed Consent\",\n",
        "        \"AI Regulations\", \"Data Ownership\", \"AI Policy Making\",\n",
        "        \"Ethical Decision Making\", \"Sustainable AI\",\n",
        "        \"Ethics in Machine Learning\", \"Fairness Metrics\",\n",
        "        \"Ethical Use of Data\", \"Data Sharing Agreements\",\n",
        "        \"Legal Compliance\", \"Open Data Principles\",\n",
        "        \"Bias Testing Tools\", \"AI Auditing\", \"Unbiased Datasets\",\n",
        "        \"Stakeholder Analysis\", \"Disparate Impact Analysis\",\n",
        "        \"Moral Responsibility\"\n",
        "    ],\n",
        "    \"Business Acumen\": [\n",
        "        \"Understanding Business Problems\", \"Domain Knowledge\",\n",
        "        \"Strategic Thinking\", \"Decision Making\",\n",
        "        \"Business Process Management\", \"Business Analytics\",\n",
        "        \"Market Analysis\", \"Financial Forecasting\", \"Competitor Analysis\",\n",
        "        \"Risk Management\", \"Customer Insights\", \"Operational Efficiency\",\n",
        "        \"Cost-Benefit Analysis\", \"Business Continuity Planning\",\n",
        "        \"SWOT Analysis\", \"Stakeholder Mapping\", \"Value Proposition Design\",\n",
        "        \"Revenue Modeling\", \"Pricing Strategies\", \"Sales Forecasting\",\n",
        "        \"Data-Driven Strategy\", \"ROI Analysis\", \"Supply Chain Optimization\",\n",
        "        \"Change Management\", \"Customer Journey Mapping\",\n",
        "        \"Business Case Development\", \"Lean Management\", \"KPI Management\",\n",
        "        \"Balanced Scorecard\"\n",
        "    ],\n",
        "    \"Communication Skills\": [\n",
        "        \"Presenting Findings\", \"Technical Writing\", \"Stakeholder Engagement\",\n",
        "        \"Collaborative Skills\", \"Cross-disciplinary Communication\",\n",
        "        \"Public Speaking\", \"Negotiation Skills\", \"Team Leadership\",\n",
        "        \"Listening Skills\", \"Conflict Resolution\", \"Feedback Giving\",\n",
        "        \"Visual Storytelling\", \"Crisis Communication\",\n",
        "        \"Documentation Skills\", \"Knowledge Sharing\", \"Empathy in Communication\",\n",
        "        \"Persuasion Skills\", \"Non-Verbal Communication\", \"Active Listening\",\n",
        "        \"Pitching Ideas\", \"Workshop Facilitation\", \"Meeting Moderation\",\n",
        "        \"Inclusive Communication\", \"Cultural Sensitivity\", \"Interpersonal Skills\",\n",
        "        \"Brainstorming Techniques\", \"Storyboarding\", \"Customer Communication\",\n",
        "        \"Clarifying Questions\", \"Audience Analysis\"\n",
        "    ],\n",
        "    \"Software Engineering\": [\n",
        "        \"Version Control\", \"Testing and Debugging\", \"Agile Methodologies\",\n",
        "        \"API Development\", \"Big Data Systems Engineering\",\n",
        "        \"Microservices Architecture\", \"Continuous Integration\",\n",
        "        \"Continuous Deployment\", \"Infrastructure as Code\",\n",
        "        \"Object-Oriented Programming\", \"Functional Programming\",\n",
        "        \"Design Patterns\", \"Code Reviews\", \"Unit Testing\",\n",
        "        \"Integration Testing\", \"Performance Testing\",\n",
        "        \"Security Testing\", \"CI/CD Pipelines\", \"Software Documentation\",\n",
        "        \"Code Optimization\", \"Embedded Systems\", \"Software Refactoring\",\n",
        "        \"Scalability Engineering\", \"Software Architecture\",\n",
        "        \"Event-Driven Programming\", \"Multi-threading\",\n",
        "        \"Asynchronous Programming\", \"Concurrency\", \"Distributed Systems\",\n",
        "        \"Cloud-Native Development\"\n",
        "    ],\n",
        "    \"Cloud Computing\": [\n",
        "        \"AWS\", \"Google Cloud Platform\", \"Microsoft Azure\", \"Cloud Infrastructure\",\n",
        "        \"Data Pipeline Development\", \"Distributed Systems\",\n",
        "        \"Serverless Computing\", \"Hybrid Cloud\", \"Private Cloud\",\n",
        "        \"Public Cloud\", \"Cloud Storage\", \"Infrastructure as a Service (IaaS)\",\n",
        "        \"Platform as a Service (PaaS)\", \"Software as a Service (SaaS)\",\n",
        "        \"Cloud Security\", \"Virtual Machines\", \"Kubernetes\",\n",
        "        \"Docker Containers\", \"Load Balancing\", \"Networking in Cloud\",\n",
        "        \"Cloud Monitoring\", \"Cloud Automation\", \"Cloud Backup Solutions\",\n",
        "        \"Disaster Recovery\", \"Edge Computing\", \"Cloud Migration\",\n",
        "        \"Identity and Access Management (IAM)\", \"Multi-Cloud Strategies\",\n",
        "        \"Resource Scaling\", \"Cloud Optimization\"\n",
        "    ],\n",
        "    \"Research Methods & Project Management\": [\n",
        "        \"Research Hypothesis Formulation\", \"Experiment Design\",\n",
        "        \"Project Planning\", \"Team Collaboration\", \"Research Reproducibility\",\n",
        "        \"Open Science Principles\", \"Scientific Data Lifecycle Management\",\n",
        "        \"Risk Assessment\", \"Stakeholder Management\", \"Milestone Tracking\",\n",
        "        \"Deliverable Planning\", \"Agile Project Management\",\n",
        "        \"Waterfall Project Management\", \"SCRUM Framework\",\n",
        "        \"Kanban Boards\", \"Gantt Charts\", \"Critical Path Method\",\n",
        "        \"Resource Allocation\", \"Project Reporting\", \"Task Prioritization\",\n",
        "        \"Budgeting\", \"Progress Monitoring\", \"Project Scope Management\",\n",
        "        \"Change Requests\", \"Project Documentation\", \"Project Closure\",\n",
        "        \"Project Handover\", \"Iterative Development\", \"Time Management\",\n",
        "        \"Team Retrospectives\"\n",
        "    ],\n",
        "    \"Big Data Technologies\": [\n",
        "        \"Hadoop\", \"Spark\", \"Kafka\", \"MapReduce\", \"TensorFlow\", \"Scikit-learn\",\n",
        "        \"Data Stream Processing\", \"High-Performance Networks\", \"Pig\",\n",
        "        \"Hive\", \"Flume\", \"HBase\", \"Cassandra\", \"Flink\",\n",
        "        \"Dask\", \"NiFi\", \"BigQuery\", \"Dataflow\", \"Storm\",\n",
        "        \"ElasticSearch\", \"Snowflake\", \"Redshift\", \"Presto\", \"Delta Lake\",\n",
        "        \"Vertica\", \"Kudu\", \"Mesos\", \"Impala\", \"Zookeeper\",\n",
        "        \"Bigtable\", \"Oozie\", \"Sqoop\", \"AWS Glue\", \"Google Data Studio\"\n",
        "    ],\n",
        "    \"Domain-Specific Knowledge\": [\n",
        "        \"Healthcare Analytics\", \"Finance Analytics\", \"E-commerce Analytics\",\n",
        "        \"Government Data Systems\", \"Open Data Utilization\", \"IoT Analytics\",\n",
        "        \"Social Media Analytics\", \"Marketing Analytics\", \"Energy Analytics\",\n",
        "        \"Telecommunications Analytics\", \"Retail Analytics\",\n",
        "        \"Supply Chain Analytics\", \"Education Analytics\", \"Transportation Analytics\",\n",
        "        \"Climate Data Analysis\", \"Agriculture Analytics\", \"Real Estate Analytics\",\n",
        "        \"Geospatial Data Analysis\", \"Cybersecurity Analytics\",\n",
        "        \"Sports Analytics\", \"Entertainment Analytics\", \"Automotive Analytics\",\n",
        "        \"Travel Analytics\", \"Manufacturing Analytics\", \"Legal Analytics\",\n",
        "        \"Insurance Analytics\", \"Gaming Analytics\", \"Aviation Analytics\",\n",
        "        \"Military Data Analysis\", \"Smart City Data Analysis\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "-GIwa7jE_ubG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the expanded reference set into a single list of competences for analysis\n",
        "expanded_competences = [skill.lower() for skills in reference_set.values() for skill in skills]\n",
        "\n",
        "# Initialize a Counter to track skill mentions using the expanded reference set\n",
        "expanded_skill_counter = Counter()\n",
        "\n",
        "# Iterate through the cleaned job descriptions and count mentions of expanded competences\n",
        "for description in df[\"Cleaned Job Description\"].dropna():\n",
        "    for skill in expanded_competences:\n",
        "        if re.search(rf'\\b{re.escape(skill)}\\b', description, re.IGNORECASE):\n",
        "            expanded_skill_counter[skill] += 1\n",
        "\n",
        "# Convert the results to a DataFrame for better visualization\n",
        "expanded_competence_df = pd.DataFrame(expanded_skill_counter.items(), columns=[\"Competence\", \"Frequency\"])\n",
        "expanded_competence_df = expanded_competence_df.sort_values(by=\"Frequency\", ascending=False)"
      ],
      "metadata": {
        "id": "JC9Tf2Ss-ZhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_competence_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rXKBnqxbFH3o",
        "outputId": "97730407-b3bf-44e8-963b-645531465f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Competence  Frequency\n",
              "0                 python        277\n",
              "3             tensorflow        120\n",
              "25                   sql        109\n",
              "7                    aws        104\n",
              "45                     r         66\n",
              "..                   ...        ...\n",
              "152             lightgbm          1\n",
              "153   data normalization          1\n",
              "155         data lineage          1\n",
              "157  performance testing          1\n",
              "186  marketing analytics          1\n",
              "\n",
              "[187 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa90f860-e810-4cd7-bbd7-5776ca358345\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Competence</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>python</td>\n",
              "      <td>277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tensorflow</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>sql</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>aws</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>r</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>lightgbm</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>data normalization</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>data lineage</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>performance testing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>marketing analytics</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>187 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa90f860-e810-4cd7-bbd7-5776ca358345')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa90f860-e810-4cd7-bbd7-5776ca358345 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa90f860-e810-4cd7-bbd7-5776ca358345');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-45c73cc0-37c3-47f2-beab-2dff3b4116e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45c73cc0-37c3-47f2-beab-2dff3b4116e4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-45c73cc0-37c3-47f2-beab-2dff3b4116e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fc4796e8-cf86-4c6b-8099-7830d4021748\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('expanded_competence_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fc4796e8-cf86-4c6b-8099-7830d4021748 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('expanded_competence_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "expanded_competence_df",
              "summary": "{\n  \"name\": \"expanded_competence_df\",\n  \"rows\": 187,\n  \"fields\": [\n    {\n      \"column\": \"Competence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 187,\n        \"samples\": [\n          \"performance testing\",\n          \"swift\",\n          \"css\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Frequency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 1,\n        \"max\": 277,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          1,\n          31,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the reference set with word2vec, it finds similar words for each competence in the reference set"
      ],
      "metadata": {
        "id": "4O2HzbRNGlb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the job descriptions for Word2Vec\n",
        "job_descriptions = df_clean[\"Cleaned Job Description\"].dropna().tolist()\n",
        "tokenized_descriptions = [simple_preprocess(description) for description in job_descriptions]\n",
        "\n",
        "# Train a Word2Vec model on the job descriptions\n",
        "w2v_model = Word2Vec(sentences=tokenized_descriptions, vector_size=100, window=5, min_count=2, workers=4, epochs=10)\n",
        "\n",
        "# Function to find similar words for a given word using Word2Vec\n",
        "def find_similar_words(word, topn=5):\n",
        "    try:\n",
        "        return [sim_word for sim_word, _ in w2v_model.wv.most_similar(word, topn=topn)]\n",
        "    except KeyError:\n",
        "        return []  # Return empty if the word is not in the vocabulary\n",
        "\n",
        "# Generate similar words for each competence in the reference set\n",
        "expanded_competences_with_synonyms = set(expanded_competences)  # Start with the existing competences\n",
        "for skill in expanded_competences:\n",
        "    similar_words = find_similar_words(skill.lower(), topn=3)  # Find 3 most similar words\n",
        "    expanded_competences_with_synonyms.update(similar_words)\n",
        "\n",
        "# Convert the set back to a list for further processing\n",
        "expanded_competences_with_synonyms = list(expanded_competences_with_synonyms)\n",
        "\n",
        "# Remove high-level categories from the expanded competence set\n",
        "high_level_categories = {\n",
        "    \"Programming\", \"Mathematics & Statistics\", \"Machine Learning\",\n",
        "    \"Data Manipulation\", \"Data Management\", \"Generative AI\",\n",
        "    \"Visualization & Storytelling\", \"Ethics & Compliance\", \"Business Acumen\",\n",
        "    \"Communication Skills\", \"Software Engineering\", \"Cloud Computing\",\n",
        "    \"Research Methods & Project Management\", \"Big Data Technologies\",\n",
        "    \"Domain-Specific Knowledge\"\n",
        "}\n",
        "\n",
        "# Filter out high-level categories from the expanded set\n",
        "filtered_expanded_competences = [\n",
        "    term for term in expanded_competences_with_synonyms\n",
        "    if term.lower() not in [category.lower() for category in high_level_categories]\n",
        "]\n",
        "\n",
        "# Display a subset of the filtered expanded competences\n",
        "filtered_expanded_competences[:50]  # Display first 50 terms for review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8Vbq-_ZGwr5",
        "outputId": "5a765517-f6a5-48e8-e6d5-356069c9939c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['infographics',\n",
              " 'etl processes',\n",
              " 'unbiased datasets',\n",
              " 'autoregressive models',\n",
              " 'multi-cloud strategies',\n",
              " 'algebra',\n",
              " 'css',\n",
              " 'language modeling',\n",
              " 'html',\n",
              " 'redshift',\n",
              " 'microservices architecture',\n",
              " 'telecommunications analytics',\n",
              " 'stakeholder management',\n",
              " 'graph',\n",
              " 'linear',\n",
              " 'bar charts',\n",
              " 'bubble charts',\n",
              " 'rust',\n",
              " 'dart',\n",
              " 'word clouds',\n",
              " 'edge computing',\n",
              " 'testing and debugging',\n",
              " 'access control',\n",
              " 'business process management',\n",
              " 'software documentation',\n",
              " 'bias testing tools',\n",
              " 'supply chain optimization',\n",
              " 'regression analysis',\n",
              " 'data security',\n",
              " 'transparency in ai',\n",
              " 'bert models',\n",
              " 'graph theory',\n",
              " 'value proposition design',\n",
              " 'multimodal ai',\n",
              " 'deepspeed',\n",
              " 'box plots',\n",
              " 'data stream processing',\n",
              " 'database',\n",
              " 'anomaly detection',\n",
              " 'relational databases',\n",
              " 'data sensitivity management',\n",
              " 'data pipeline development',\n",
              " 'data schema design',\n",
              " 'vbscript',\n",
              " 'roi analysis',\n",
              " 'perl',\n",
              " 'histograms',\n",
              " 'model optimization',\n",
              " 'fusion',\n",
              " 'zero-shot learning']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def categorize_phrases(reference_set, filtered_expanded_competences, clean_refined_phrases):\n",
        "  \"\"\"Categorizes phrases based on cosine similarity to existing categories.\"\"\"\n",
        "\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  # Combine all terms for vectorization\n",
        "  all_terms = list(reference_set.keys()) + filtered_expanded_competences + clean_refined_phrases\n",
        "  tfidf_matrix = vectorizer.fit_transform(all_terms)\n",
        "\n",
        "  # Calculate cosine similarity between new phrases and existing categories\n",
        "  reference_indices = {category: index for index, category in enumerate(reference_set.keys())}\n",
        "  new_phrase_indices = {phrase: index + len(reference_set) for index, phrase in enumerate(filtered_expanded_competences + clean_refined_phrases)}\n",
        "\n",
        "  categorized_phrases = {}\n",
        "  for phrase, index in new_phrase_indices.items():\n",
        "    similarities = cosine_similarity(tfidf_matrix[index], tfidf_matrix[:len(reference_set)])\n",
        "\n",
        "    # Convert reference_set.keys() to a list to make it subscriptable\n",
        "    best_category = list(reference_set.keys())[similarities.argmax()]\n",
        "\n",
        "    if phrase not in categorized_phrases:\n",
        "      categorized_phrases[phrase] = []\n",
        "    categorized_phrases[phrase].append(best_category) # Append the most similar category\n",
        "\n",
        "  # Update the reference_set\n",
        "  updated_reference_set = reference_set.copy()\n",
        "  for phrase, categories in categorized_phrases.items():\n",
        "    best_match = categories[0]  # Taking the first (most similar) category\n",
        "    if phrase not in updated_reference_set[best_match]:\n",
        "      updated_reference_set[best_match].append(phrase)\n",
        "\n",
        "  return updated_reference_set"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tKOQXoNHnfz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage (assuming you have defined reference_set, filtered_expanded_competences, and clean_refined_phrases)\n",
        "updated_reference_set = categorize_phrases(reference_set, filtered_expanded_competences, clean_refined_phrases)\n",
        "updated_reference_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv6TcIXtnubr",
        "outputId": "55c33e23-d51f-40f1-db62-32c63b3440db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Programming': ['Python',\n",
              "  'R',\n",
              "  'SQL',\n",
              "  'Java',\n",
              "  'C++',\n",
              "  'JavaScript',\n",
              "  'C#',\n",
              "  'MATLAB',\n",
              "  'Perl',\n",
              "  'Ruby',\n",
              "  'Go',\n",
              "  'Scala',\n",
              "  'Swift',\n",
              "  'HTML',\n",
              "  'CSS',\n",
              "  'Dart',\n",
              "  'Kotlin',\n",
              "  'Shell Scripting',\n",
              "  'Rust',\n",
              "  'TypeScript',\n",
              "  'Bash',\n",
              "  'Fortran',\n",
              "  'Lua',\n",
              "  'VBScript',\n",
              "  'Julia',\n",
              "  'Assembly',\n",
              "  'F#',\n",
              "  'Delphi',\n",
              "  'Objective-C',\n",
              "  'COBOL',\n",
              "  'infographics',\n",
              "  'etl processes',\n",
              "  'unbiased datasets',\n",
              "  'autoregressive models',\n",
              "  'algebra',\n",
              "  'css',\n",
              "  'language modeling',\n",
              "  'html',\n",
              "  'redshift',\n",
              "  'microservices architecture',\n",
              "  'telecommunications analytics',\n",
              "  'graph',\n",
              "  'linear',\n",
              "  'bar charts',\n",
              "  'bubble charts',\n",
              "  'rust',\n",
              "  'dart',\n",
              "  'word clouds',\n",
              "  'testing and debugging',\n",
              "  'access control',\n",
              "  'bias testing tools',\n",
              "  'supply chain optimization',\n",
              "  'regression analysis',\n",
              "  'bert models',\n",
              "  'graph theory',\n",
              "  'value proposition design',\n",
              "  'deepspeed',\n",
              "  'box plots',\n",
              "  'database',\n",
              "  'anomaly detection',\n",
              "  'relational databases',\n",
              "  'vbscript',\n",
              "  'roi analysis',\n",
              "  'perl',\n",
              "  'histograms',\n",
              "  'model optimization',\n",
              "  'fusion',\n",
              "  'masked language modeling',\n",
              "  'time series forecasting',\n",
              "  'code optimization',\n",
              "  'annotated charts',\n",
              "  'disaster recovery',\n",
              "  'gantt charts',\n",
              "  'critical path method',\n",
              "  'linear algebra',\n",
              "  'snowflake',\n",
              "  'spss',\n",
              "  'treemaps',\n",
              "  'monte carlo simulation',\n",
              "  'ray',\n",
              "  'outlier detection',\n",
              "  'scatter plots',\n",
              "  'nltk',\n",
              "  'operational efficiency',\n",
              "  'javascript',\n",
              "  'object-oriented programming',\n",
              "  'probability',\n",
              "  'moving',\n",
              "  'disparate impact analysis',\n",
              "  'dashboard design',\n",
              "  'gans for images',\n",
              "  'geospatial visuals',\n",
              "  'episodic memory models',\n",
              "  'fairness metrics',\n",
              "  'flume',\n",
              "  'schema evolution',\n",
              "  'revenue modeling',\n",
              "  'langchain',\n",
              "  'mesos',\n",
              "  'instance',\n",
              "  'r',\n",
              "  'presenting findings',\n",
              "  'brainstorming techniques',\n",
              "  'natural language generation',\n",
              "  'iterative development',\n",
              "  'slicing and indexing',\n",
              "  'spark',\n",
              "  'transportation analytics',\n",
              "  'bash',\n",
              "  'travel analytics',\n",
              "  'mathematical programming',\n",
              "  'event-driven programming',\n",
              "  'agriculture analytics',\n",
              "  'e-commerce analytics',\n",
              "  'frontend',\n",
              "  'workshop facilitation',\n",
              "  'one-hot encoding',\n",
              "  'kudu',\n",
              "  'blueprint',\n",
              "  'security testing',\n",
              "  'manufacturing analytics',\n",
              "  'beam',\n",
              "  'visual encodings',\n",
              "  'ruby',\n",
              "  'sagemaker',\n",
              "  'logistic regression',\n",
              "  'neural networks',\n",
              "  'game theory',\n",
              "  'llm applications',\n",
              "  'impala',\n",
              "  'high-performance networks',\n",
              "  'active listening',\n",
              "  'scala',\n",
              "  'stakeholder engagement',\n",
              "  'embedding',\n",
              "  'model deployment',\n",
              "  'ela',\n",
              "  'distributed systems',\n",
              "  'nosql',\n",
              "  'bigquery',\n",
              "  'opensearch',\n",
              "  'agile methodologies',\n",
              "  'presto',\n",
              "  'go',\n",
              "  'c#',\n",
              "  'time series analysis',\n",
              "  'scikitlearn',\n",
              "  'matplotlib',\n",
              "  'change requests',\n",
              "  'drill-down visuals',\n",
              "  'common',\n",
              "  'f#',\n",
              "  'ipr protection',\n",
              "  '3d visualizations',\n",
              "  'cybersecurity',\n",
              "  'storyboarding',\n",
              "  'descriptive analytics',\n",
              "  'balanced scorecard',\n",
              "  'load balancing',\n",
              "  'jax',\n",
              "  'anova',\n",
              "  'zookeeper',\n",
              "  'stakeholder mapping',\n",
              "  'marketing analytics',\n",
              "  'continues',\n",
              "  'heatmaps',\n",
              "  'amazon',\n",
              "  'probability distributions',\n",
              "  'lean',\n",
              "  'multi-view charts',\n",
              "  'audience analysis',\n",
              "  'resource allocation',\n",
              "  'delta lake',\n",
              "  'cs',\n",
              "  'embedded systems',\n",
              "  'coordination',\n",
              "  'dimensionality reduction',\n",
              "  'choropleth maps',\n",
              "  'financial forecasting',\n",
              "  'pitching ideas',\n",
              "  'memory',\n",
              "  'statistical modeling',\n",
              "  'oozie',\n",
              "  'functional programming',\n",
              "  'sports analytics',\n",
              "  'tokenization',\n",
              "  'docker containers',\n",
              "  'followed',\n",
              "  'cassandra',\n",
              "  'virtual machines',\n",
              "  'infrastructure as code',\n",
              "  'tensorflow',\n",
              "  'integration testing',\n",
              "  'fine-tuning',\n",
              "  'indexing',\n",
              "  'text-to-image generation',\n",
              "  'adopting',\n",
              "  'meeting moderation',\n",
              "  'retail analytics',\n",
              "  'strategic thinking',\n",
              "  'seq2seq models',\n",
              "  'kafka',\n",
              "  'dataflow',\n",
              "  'waterfall charts',\n",
              "  'market analysis',\n",
              "  'postgresql',\n",
              "  'pig',\n",
              "  'java',\n",
              "  'mapreduce',\n",
              "  'backup and recovery',\n",
              "  'dalle',\n",
              "  'xml',\n",
              "  'legal analytics',\n",
              "  'continuous deployment',\n",
              "  'interactive dashboards',\n",
              "  'sales forecasting',\n",
              "  'bagging',\n",
              "  'kotlin',\n",
              "  'stream processing',\n",
              "  'dask',\n",
              "  'customer insights',\n",
              "  'continuous integration',\n",
              "  'lightgbm',\n",
              "  'experiment design',\n",
              "  'hive',\n",
              "  'informed consent',\n",
              "  'sqoop',\n",
              "  'concurrency',\n",
              "  'customer journey mapping',\n",
              "  'aws',\n",
              "  'gradient boosting',\n",
              "  'kanban boards',\n",
              "  'catboost',\n",
              "  'technical writing',\n",
              "  'cross validation',\n",
              "  'react',\n",
              "  'looker',\n",
              "  'stakeholder analysis',\n",
              "  'clustering techniques',\n",
              "  'binning',\n",
              "  'bidirectional models',\n",
              "  'energy analytics',\n",
              "  'speech synthesis',\n",
              "  'storm',\n",
              "  'resource scaling',\n",
              "  'pretrained models',\n",
              "  'matlab',\n",
              "  'hadoop',\n",
              "  'variance analysis',\n",
              "  'node',\n",
              "  'model pruning',\n",
              "  'hierarchical databases',\n",
              "  'fortran',\n",
              "  'audio generation',\n",
              "  'lua',\n",
              "  'supply chain analytics',\n",
              "  'support vector machines (svm)',\n",
              "  'kera',\n",
              "  'text summarization',\n",
              "  'aws glue',\n",
              "  'k-nearest neighbors',\n",
              "  'milestone tracking',\n",
              "  'distributed databases',\n",
              "  'calculus',\n",
              "  'platform as a service (paas)',\n",
              "  'c++',\n",
              "  'custom visuals',\n",
              "  'unit testing',\n",
              "  'assembly',\n",
              "  'pivot tables',\n",
              "  'processor',\n",
              "  'cultural sensitivity',\n",
              "  'clarifying questions',\n",
              "  'asynchronous programming',\n",
              "  'image captioning',\n",
              "  'dag',\n",
              "  'julia',\n",
              "  'gaming analytics',\n",
              "  'random forests',\n",
              "  'roberta',\n",
              "  'finance analytics',\n",
              "  'social media analytics',\n",
              "  'bigtable',\n",
              "  'code reviews',\n",
              "  'team retrospectives',\n",
              "  'public speaking',\n",
              "  'ready',\n",
              "  'budgeting',\n",
              "  'bias mitigation',\n",
              "  'scrum framework',\n",
              "  'exposure',\n",
              "  'delta',\n",
              "  'shell scripting',\n",
              "  'conflict resolution',\n",
              "  'xgboost',\n",
              "  'pricing strategies',\n",
              "  'delphi',\n",
              "  'acoustic',\n",
              "  'cross-filtering',\n",
              "  'language understanding',\n",
              "  'risk assessment',\n",
              "  'databricks',\n",
              "  'hbase',\n",
              "  'numerical analysis',\n",
              "  'adversarial robustness',\n",
              "  'education analytics',\n",
              "  'predictive analytics',\n",
              "  'entertainment analytics',\n",
              "  'etl pipelines',\n",
              "  'cybersecurity analytics',\n",
              "  'merlin',\n",
              "  'optimization techniques',\n",
              "  'markov chains',\n",
              "  'securing',\n",
              "  'decision making',\n",
              "  'predictive models',\n",
              "  'gpt models',\n",
              "  'lake',\n",
              "  'network graphs',\n",
              "  'statistical inference',\n",
              "  'transformer architectures',\n",
              "  'discrete',\n",
              "  'iot analytics',\n",
              "  'diffusion models',\n",
              "  'sql',\n",
              "  'infrastructure as a service (iaas)',\n",
              "  'vector',\n",
              "  'cluster analysis',\n",
              "  'kubernetes',\n",
              "  'stochastic processes',\n",
              "  'flink',\n",
              "  'apache',\n",
              "  'cobol',\n",
              "  'airflow',\n",
              "  'real-time dashboards',\n",
              "  'aviation analytics',\n",
              "  'proficient',\n",
              "  'automl',\n",
              "  'pie charts',\n",
              "  'prescriptive analytics',\n",
              "  'graphql',\n",
              "  'vertica',\n",
              "  'team collaboration',\n",
              "  'python',\n",
              "  'object-oriented databases',\n",
              "  'insurance analytics',\n",
              "  'objective-c',\n",
              "  'hypothesis testing',\n",
              "  'scikit-learn',\n",
              "  'js',\n",
              "  'competitor analysis',\n",
              "  'geospatial',\n",
              "  'design patterns',\n",
              "  'csearch',\n",
              "  'principal component analysis (pca)',\n",
              "  'hyperparameter tuning',\n",
              "  'swift',\n",
              "  'open science principles',\n",
              "  'graph databases',\n",
              "  'time-series visualizations',\n",
              "  'modelling',\n",
              "  'schema',\n",
              "  'task prioritization',\n",
              "  'nifi',\n",
              "  'api development',\n",
              "  'performance testing',\n",
              "  'interpretive',\n",
              "  'matrix decomposition',\n",
              "  'progress monitoring',\n",
              "  'elasticsearch',\n",
              "  'version control',\n",
              "  'interactive visualizations',\n",
              "  'cost-benefit analysis',\n",
              "  'ci/cd pipelines',\n",
              "  'algorithmic fairness',\n",
              "  'real estate analytics',\n",
              "  'pytorch',\n",
              "  'line charts',\n",
              "  'text classification',\n",
              "  'automotive analytics',\n",
              "  'microsoft azure',\n",
              "  'feature scaling',\n",
              "  'deliverable planning',\n",
              "  'ethical decision making',\n",
              "  'swot analysis',\n",
              "  'typescript',\n",
              "  'mongodb',\n",
              "  'factor analysis',\n",
              "  'kubeflow',\n",
              "  'feature selection',\n",
              "  'feedback giving',\n",
              "  'team leadership',\n",
              "  'moral responsibility',\n",
              "  'multi-threading',\n",
              "  'docker',\n",
              "  'healthcare analytics',\n",
              "  'llm',\n",
              "  'processing',\n",
              "  'language processing',\n",
              "  'natural language processing',\n",
              "  'model llm',\n",
              "  'language model llm',\n",
              "  'language processing nlp',\n",
              "  'processing nlp',\n",
              "  'preprocessing',\n",
              "  'cloudbased',\n",
              "  'processing computer',\n",
              "  'llm multimodal',\n",
              "  'processing computer vision',\n",
              "  'processing nlp computer',\n",
              "  'language processing computer'],\n",
              " 'Mathematics & Statistics': ['Probability',\n",
              "  'Linear Algebra',\n",
              "  'Hypothesis Testing',\n",
              "  'Descriptive Analytics',\n",
              "  'Statistical Modeling',\n",
              "  'Bayesian Statistics',\n",
              "  'Monte Carlo Simulation',\n",
              "  'Optimization Techniques',\n",
              "  'Game Theory',\n",
              "  'Markov Chains',\n",
              "  'Time Series Analysis',\n",
              "  'Stochastic Processes',\n",
              "  'Cluster Analysis',\n",
              "  'Principal Component Analysis (PCA)',\n",
              "  'Dimensionality Reduction',\n",
              "  'Numerical Analysis',\n",
              "  'Regression Analysis',\n",
              "  'Variance Analysis',\n",
              "  'Matrix Decomposition',\n",
              "  'Graph Theory',\n",
              "  'Probability Distributions',\n",
              "  'Sampling Methods',\n",
              "  'ANOVA',\n",
              "  'Non-parametric Statistics',\n",
              "  'Factor Analysis',\n",
              "  'Spatial Statistics',\n",
              "  'Quantitative Methods',\n",
              "  'Predictive Models',\n",
              "  'Statistical Inference',\n",
              "  'Mathematical Programming',\n",
              "  'bayesian statistics',\n",
              "  'spatial statistics',\n",
              "  'non-parametric statistics',\n",
              "  'engineering mathematics'],\n",
              " 'Machine Learning': ['Logistic Regression',\n",
              "  'Random Forests',\n",
              "  'Neural Networks',\n",
              "  'Supervised Learning',\n",
              "  'Unsupervised Learning',\n",
              "  'Reinforcement Learning',\n",
              "  'Model Deployment',\n",
              "  'Predictive Analytics',\n",
              "  'Prescriptive Analytics',\n",
              "  'Support Vector Machines (SVM)',\n",
              "  'Gradient Boosting',\n",
              "  'XGBoost',\n",
              "  'CatBoost',\n",
              "  'LightGBM',\n",
              "  'K-Nearest Neighbors',\n",
              "  'Clustering Techniques',\n",
              "  'AutoML',\n",
              "  'Model Optimization',\n",
              "  'Deep Reinforcement Learning',\n",
              "  'GANs (Generative Adversarial Networks)',\n",
              "  'Transfer Learning',\n",
              "  'Hyperparameter Tuning',\n",
              "  'Semi-supervised Learning',\n",
              "  'Anomaly Detection',\n",
              "  'Online Learning',\n",
              "  'Active Learning',\n",
              "  'Feature Selection',\n",
              "  'Time Series Forecasting',\n",
              "  'Bagging',\n",
              "  'Ensemble Methods',\n",
              "  'zero-shot learning',\n",
              "  'reinforcement learning',\n",
              "  'semi-supervised learning',\n",
              "  'ethics in machine learning',\n",
              "  'unsupervised learning',\n",
              "  'deep reinforcement learning',\n",
              "  'few-shot learning',\n",
              "  'transfer learning',\n",
              "  'supervised learning',\n",
              "  'online learning',\n",
              "  'active learning',\n",
              "  'contrastive learning',\n",
              "  'machine learning',\n",
              "  'machine learning model',\n",
              "  'machine learning engineer',\n",
              "  'ai machine learning',\n",
              "  'machine learning algorithm',\n",
              "  'experience machine learning',\n",
              "  'machine learning deep',\n",
              "  'machine learning technique',\n",
              "  'machine learning ml',\n",
              "  'intelligence machine learning',\n",
              "  'machine learning ai',\n",
              "  'machine learning data',\n",
              "  'science machine learning',\n",
              "  'machine learning framework',\n",
              "  'understanding machine learning',\n",
              "  'machine learning computer',\n",
              "  'machine learning research',\n",
              "  'data science machine',\n",
              "  'advanced machine learning',\n",
              "  'machine learning related',\n",
              "  'knowledge machine learning',\n",
              "  'data machine learning'],\n",
              " 'Data Manipulation': ['Data Cleaning',\n",
              "  'Feature Engineering',\n",
              "  'Data Wrangling',\n",
              "  'Data Integration',\n",
              "  'Data Transformation',\n",
              "  'Dimensionality Reduction',\n",
              "  'Data Sampling',\n",
              "  'Data Normalization',\n",
              "  'Data Imputation',\n",
              "  'Pivot Tables',\n",
              "  'Data Merging',\n",
              "  'Data Aggregation',\n",
              "  'Outlier Detection',\n",
              "  'Reshaping Data',\n",
              "  'Slicing and Indexing',\n",
              "  'Handling Missing Data',\n",
              "  'Data Encoding',\n",
              "  'One-Hot Encoding',\n",
              "  'Binning',\n",
              "  'Data Scaling',\n",
              "  'Data Partitioning',\n",
              "  'ETL Processes',\n",
              "  'Data Augmentation',\n",
              "  'Feature Scaling',\n",
              "  'Cross Validation',\n",
              "  'Data Reduction',\n",
              "  'Data Balancing',\n",
              "  'Data Resampling',\n",
              "  'Data Annotation',\n",
              "  'Data Schema Design'],\n",
              " 'Data Management': ['Data Governance',\n",
              "  'Metadata Management',\n",
              "  'FAIR Data Principles',\n",
              "  'Data Provenance',\n",
              "  'Data Warehousing',\n",
              "  'Data Lakes',\n",
              "  'Data Curation',\n",
              "  'Data Quality Assurance',\n",
              "  'Data Stewardship',\n",
              "  'Master Data Management',\n",
              "  'Data Lineage',\n",
              "  'ETL Pipelines',\n",
              "  'Data Versioning',\n",
              "  'Backup and Recovery',\n",
              "  'Access Control',\n",
              "  'Data Partitioning',\n",
              "  'Schema Evolution',\n",
              "  'Distributed Databases',\n",
              "  'Data Archiving',\n",
              "  'Data Replication',\n",
              "  'Stream Processing',\n",
              "  'Data Security',\n",
              "  'Data Auditing',\n",
              "  'Data Masking',\n",
              "  'Data Sensitivity Management',\n",
              "  'Data Dictionary',\n",
              "  'Hierarchical Databases',\n",
              "  'Relational Databases',\n",
              "  'Object-Oriented Databases',\n",
              "  'Graph Databases',\n",
              "  'stakeholder management',\n",
              "  'business process management',\n",
              "  'data security',\n",
              "  'data stream processing',\n",
              "  'data sensitivity management',\n",
              "  'data pipeline development',\n",
              "  'data schema design',\n",
              "  'data transformation',\n",
              "  'kpi management',\n",
              "  'data imputation',\n",
              "  'data lakes',\n",
              "  'military data analysis',\n",
              "  'data reduction',\n",
              "  'data cleaning',\n",
              "  'data dictionary',\n",
              "  'data encoding',\n",
              "  'data sharing agreements',\n",
              "  'data augmentation',\n",
              "  'data auditing',\n",
              "  'climate data analysis',\n",
              "  'data merging',\n",
              "  'data resampling',\n",
              "  'scientific data lifecycle management',\n",
              "  'fair data principles',\n",
              "  'data lineage',\n",
              "  'data sampling',\n",
              "  'time management',\n",
              "  'identity and access management (iam)',\n",
              "  'risk management',\n",
              "  'data versioning',\n",
              "  'geospatial data analysis',\n",
              "  'data normalization',\n",
              "  'data partitioning',\n",
              "  'change management',\n",
              "  'open data principles',\n",
              "  'data provenance',\n",
              "  'metadata management',\n",
              "  'data scaling',\n",
              "  'google data studio',\n",
              "  'data archiving',\n",
              "  'data annotation',\n",
              "  'data ownership',\n",
              "  'data privacy',\n",
              "  'lean management',\n",
              "  'data warehousing',\n",
              "  'data balancing',\n",
              "  'smart city data analysis',\n",
              "  'data stewardship',\n",
              "  'data curation',\n",
              "  'data replication',\n",
              "  'data governance',\n",
              "  'master data management',\n",
              "  'handling missing data',\n",
              "  'ethical use of data',\n",
              "  'open data utilization',\n",
              "  'reshaping data',\n",
              "  'data aggregation',\n",
              "  'data integration',\n",
              "  'government data systems',\n",
              "  'data masking',\n",
              "  'data wrangling',\n",
              "  'data-driven strategy',\n",
              "  'data quality assurance',\n",
              "  'data science',\n",
              "  'data analysis',\n",
              "  'data processing',\n",
              "  'science data science',\n",
              "  'data science related',\n",
              "  'data science team',\n",
              "  'data science solution',\n",
              "  'exploratory data analysis'],\n",
              " 'Generative AI': ['Transformer Architectures',\n",
              "  'Fine-tuning',\n",
              "  'Prompt Engineering',\n",
              "  'Tokenization',\n",
              "  'LLM Applications',\n",
              "  'GPT Models',\n",
              "  'BERT Models',\n",
              "  'Zero-Shot Learning',\n",
              "  'Few-Shot Learning',\n",
              "  'Masked Language Modeling',\n",
              "  'Seq2Seq Models',\n",
              "  'Text-to-Image Generation',\n",
              "  'GANs for Images',\n",
              "  'Diffusion Models',\n",
              "  'Natural Language Generation',\n",
              "  'Speech Synthesis',\n",
              "  'Image Captioning',\n",
              "  'Audio Generation',\n",
              "  'Pretrained Models',\n",
              "  'Text Summarization',\n",
              "  'Knowledge Distillation',\n",
              "  'Model Pruning',\n",
              "  'Language Understanding',\n",
              "  'Data Augmentation for AI',\n",
              "  'Contrastive Learning',\n",
              "  'Episodic Memory Models',\n",
              "  'Autoregressive Models',\n",
              "  'Bidirectional Models',\n",
              "  'Language Modeling',\n",
              "  'Text Classification',\n",
              "  'Multimodal AI',\n",
              "  'transparency in ai',\n",
              "  'multimodal ai',\n",
              "  'ai auditing',\n",
              "  'gans (generative adversarial networks)',\n",
              "  'explainable ai',\n",
              "  'data augmentation for ai',\n",
              "  'ethical ai',\n",
              "  'responsible ai',\n",
              "  'ai regulations',\n",
              "  'sustainable ai',\n",
              "  'ai policy making',\n",
              "  'generative ai',\n",
              "  'generative ai solution',\n",
              "  'generative ai model',\n",
              "  'experience generative ai',\n",
              "  'generative ai technology',\n",
              "  'llm generative',\n",
              "  'llm generative ai',\n",
              "  'generative ai application',\n",
              "  'learning generative ai',\n",
              "  'ai llm'],\n",
              " 'Visualization & Storytelling': ['Data Visualization',\n",
              "  'Dashboard Design',\n",
              "  'Data Storytelling',\n",
              "  'Interactive Visualizations',\n",
              "  'Heatmaps',\n",
              "  'Choropleth Maps',\n",
              "  'Scatter Plots',\n",
              "  'Bar Charts',\n",
              "  'Line Charts',\n",
              "  'Pie Charts',\n",
              "  'Treemaps',\n",
              "  'Histograms',\n",
              "  'Box Plots',\n",
              "  'Waterfall Charts',\n",
              "  'Bubble Charts',\n",
              "  'Word Clouds',\n",
              "  'Network Graphs',\n",
              "  'Geospatial Visuals',\n",
              "  '3D Visualizations',\n",
              "  'Annotated Charts',\n",
              "  'Drill-Down Visuals',\n",
              "  'Real-Time Dashboards',\n",
              "  'Storyboarding',\n",
              "  'Infographics',\n",
              "  'Time-Series Visualizations',\n",
              "  'Cross-Filtering',\n",
              "  'Multi-View Charts',\n",
              "  'Visual Encodings',\n",
              "  'Interactive Dashboards',\n",
              "  'Custom Visuals',\n",
              "  'data visualization',\n",
              "  'visual storytelling',\n",
              "  'data storytelling',\n",
              "  'data visualization tool'],\n",
              " 'Ethics & Compliance': ['Bias Mitigation',\n",
              "  'Data Privacy',\n",
              "  'Ethical AI',\n",
              "  'GDPR Compliance',\n",
              "  'Responsible AI',\n",
              "  'IPR Protection',\n",
              "  'Algorithmic Fairness',\n",
              "  'Transparency in AI',\n",
              "  'Explainable AI',\n",
              "  'Adversarial Robustness',\n",
              "  'Cybersecurity',\n",
              "  'Data Security',\n",
              "  'Informed Consent',\n",
              "  'AI Regulations',\n",
              "  'Data Ownership',\n",
              "  'AI Policy Making',\n",
              "  'Ethical Decision Making',\n",
              "  'Sustainable AI',\n",
              "  'Ethics in Machine Learning',\n",
              "  'Fairness Metrics',\n",
              "  'Ethical Use of Data',\n",
              "  'Data Sharing Agreements',\n",
              "  'Legal Compliance',\n",
              "  'Open Data Principles',\n",
              "  'Bias Testing Tools',\n",
              "  'AI Auditing',\n",
              "  'Unbiased Datasets',\n",
              "  'Stakeholder Analysis',\n",
              "  'Disparate Impact Analysis',\n",
              "  'Moral Responsibility',\n",
              "  'gdpr compliance',\n",
              "  'legal compliance'],\n",
              " 'Business Acumen': ['Understanding Business Problems',\n",
              "  'Domain Knowledge',\n",
              "  'Strategic Thinking',\n",
              "  'Decision Making',\n",
              "  'Business Process Management',\n",
              "  'Business Analytics',\n",
              "  'Market Analysis',\n",
              "  'Financial Forecasting',\n",
              "  'Competitor Analysis',\n",
              "  'Risk Management',\n",
              "  'Customer Insights',\n",
              "  'Operational Efficiency',\n",
              "  'Cost-Benefit Analysis',\n",
              "  'Business Continuity Planning',\n",
              "  'SWOT Analysis',\n",
              "  'Stakeholder Mapping',\n",
              "  'Value Proposition Design',\n",
              "  'Revenue Modeling',\n",
              "  'Pricing Strategies',\n",
              "  'Sales Forecasting',\n",
              "  'Data-Driven Strategy',\n",
              "  'ROI Analysis',\n",
              "  'Supply Chain Optimization',\n",
              "  'Change Management',\n",
              "  'Customer Journey Mapping',\n",
              "  'Business Case Development',\n",
              "  'Lean Management',\n",
              "  'KPI Management',\n",
              "  'Balanced Scorecard',\n",
              "  'understanding business problems',\n",
              "  'business case development',\n",
              "  'business continuity planning',\n",
              "  'business analytics'],\n",
              " 'Communication Skills': ['Presenting Findings',\n",
              "  'Technical Writing',\n",
              "  'Stakeholder Engagement',\n",
              "  'Collaborative Skills',\n",
              "  'Cross-disciplinary Communication',\n",
              "  'Public Speaking',\n",
              "  'Negotiation Skills',\n",
              "  'Team Leadership',\n",
              "  'Listening Skills',\n",
              "  'Conflict Resolution',\n",
              "  'Feedback Giving',\n",
              "  'Visual Storytelling',\n",
              "  'Crisis Communication',\n",
              "  'Documentation Skills',\n",
              "  'Knowledge Sharing',\n",
              "  'Empathy in Communication',\n",
              "  'Persuasion Skills',\n",
              "  'Non-Verbal Communication',\n",
              "  'Active Listening',\n",
              "  'Pitching Ideas',\n",
              "  'Workshop Facilitation',\n",
              "  'Meeting Moderation',\n",
              "  'Inclusive Communication',\n",
              "  'Cultural Sensitivity',\n",
              "  'Interpersonal Skills',\n",
              "  'Brainstorming Techniques',\n",
              "  'Storyboarding',\n",
              "  'Customer Communication',\n",
              "  'Clarifying Questions',\n",
              "  'Audience Analysis',\n",
              "  'collaborative skills',\n",
              "  'inclusive communication',\n",
              "  'cross-disciplinary communication',\n",
              "  'non-verbal communication',\n",
              "  'interpersonal skills',\n",
              "  'crisis communication',\n",
              "  'persuasion skills',\n",
              "  'listening skills',\n",
              "  'customer communication',\n",
              "  'negotiation skills',\n",
              "  'documentation skills',\n",
              "  'empathy in communication'],\n",
              " 'Software Engineering': ['Version Control',\n",
              "  'Testing and Debugging',\n",
              "  'Agile Methodologies',\n",
              "  'API Development',\n",
              "  'Big Data Systems Engineering',\n",
              "  'Microservices Architecture',\n",
              "  'Continuous Integration',\n",
              "  'Continuous Deployment',\n",
              "  'Infrastructure as Code',\n",
              "  'Object-Oriented Programming',\n",
              "  'Functional Programming',\n",
              "  'Design Patterns',\n",
              "  'Code Reviews',\n",
              "  'Unit Testing',\n",
              "  'Integration Testing',\n",
              "  'Performance Testing',\n",
              "  'Security Testing',\n",
              "  'CI/CD Pipelines',\n",
              "  'Software Documentation',\n",
              "  'Code Optimization',\n",
              "  'Embedded Systems',\n",
              "  'Software Refactoring',\n",
              "  'Scalability Engineering',\n",
              "  'Software Architecture',\n",
              "  'Event-Driven Programming',\n",
              "  'Multi-threading',\n",
              "  'Asynchronous Programming',\n",
              "  'Concurrency',\n",
              "  'Distributed Systems',\n",
              "  'Cloud-Native Development',\n",
              "  'software documentation',\n",
              "  'software architecture',\n",
              "  'scalability engineering',\n",
              "  'software as a service (saas)',\n",
              "  'feature engineering',\n",
              "  'software refactoring',\n",
              "  'prompt engineering',\n",
              "  'engineering',\n",
              "  'software engineering',\n",
              "  'data engineering',\n",
              "  'engineering team',\n",
              "  'science engineering',\n",
              "  'engineering related',\n",
              "  'computer engineering',\n",
              "  'computer science engineering',\n",
              "  'electrical engineering',\n",
              "  'engineering related field',\n",
              "  'engineering computer',\n",
              "  'engineering experience',\n",
              "  'science computer engineering',\n",
              "  'engineering computer science',\n",
              "  'engineering data',\n",
              "  'engineering relevant',\n",
              "  'product engineering',\n",
              "  'engineering product',\n",
              "  'engineering best',\n",
              "  'engineering best practice',\n",
              "  'science engineering related',\n",
              "  'computer engineering relevant',\n",
              "  'engineering relevant technical',\n",
              "  'science electrical engineering',\n",
              "  'engineering data science'],\n",
              " 'Cloud Computing': ['AWS',\n",
              "  'Google Cloud Platform',\n",
              "  'Microsoft Azure',\n",
              "  'Cloud Infrastructure',\n",
              "  'Data Pipeline Development',\n",
              "  'Distributed Systems',\n",
              "  'Serverless Computing',\n",
              "  'Hybrid Cloud',\n",
              "  'Private Cloud',\n",
              "  'Public Cloud',\n",
              "  'Cloud Storage',\n",
              "  'Infrastructure as a Service (IaaS)',\n",
              "  'Platform as a Service (PaaS)',\n",
              "  'Software as a Service (SaaS)',\n",
              "  'Cloud Security',\n",
              "  'Virtual Machines',\n",
              "  'Kubernetes',\n",
              "  'Docker Containers',\n",
              "  'Load Balancing',\n",
              "  'Networking in Cloud',\n",
              "  'Cloud Monitoring',\n",
              "  'Cloud Automation',\n",
              "  'Cloud Backup Solutions',\n",
              "  'Disaster Recovery',\n",
              "  'Edge Computing',\n",
              "  'Cloud Migration',\n",
              "  'Identity and Access Management (IAM)',\n",
              "  'Multi-Cloud Strategies',\n",
              "  'Resource Scaling',\n",
              "  'Cloud Optimization',\n",
              "  'multi-cloud strategies',\n",
              "  'edge computing',\n",
              "  'public cloud',\n",
              "  'cloud infrastructure',\n",
              "  'cloud automation',\n",
              "  'cloud backup solutions',\n",
              "  'cloud security',\n",
              "  'cloud storage',\n",
              "  'private cloud',\n",
              "  'cloud optimization',\n",
              "  'hybrid cloud',\n",
              "  'cloud',\n",
              "  'serverless computing',\n",
              "  'networking in cloud',\n",
              "  'cloud-native development',\n",
              "  'google cloud platform',\n",
              "  'cloud monitoring',\n",
              "  'cloud migration',\n",
              "  'cloud platform',\n",
              "  'cloud computing',\n",
              "  'experience cloud',\n",
              "  'google cloud',\n",
              "  'cloud service',\n",
              "  'cloud environment',\n",
              "  'adopted cloud',\n",
              "  'adopted cloud platform',\n",
              "  'broadly adopted cloud',\n",
              "  'cloud computing stopped',\n",
              "  'cloud platform pioneered',\n",
              "  'pioneered cloud',\n",
              "  'pioneered cloud computing',\n",
              "  'platform pioneered cloud'],\n",
              " 'Research Methods & Project Management': ['Research Hypothesis Formulation',\n",
              "  'Experiment Design',\n",
              "  'Project Planning',\n",
              "  'Team Collaboration',\n",
              "  'Research Reproducibility',\n",
              "  'Open Science Principles',\n",
              "  'Scientific Data Lifecycle Management',\n",
              "  'Risk Assessment',\n",
              "  'Stakeholder Management',\n",
              "  'Milestone Tracking',\n",
              "  'Deliverable Planning',\n",
              "  'Agile Project Management',\n",
              "  'Waterfall Project Management',\n",
              "  'SCRUM Framework',\n",
              "  'Kanban Boards',\n",
              "  'Gantt Charts',\n",
              "  'Critical Path Method',\n",
              "  'Resource Allocation',\n",
              "  'Project Reporting',\n",
              "  'Task Prioritization',\n",
              "  'Budgeting',\n",
              "  'Progress Monitoring',\n",
              "  'Project Scope Management',\n",
              "  'Change Requests',\n",
              "  'Project Documentation',\n",
              "  'Project Closure',\n",
              "  'Project Handover',\n",
              "  'Iterative Development',\n",
              "  'Time Management',\n",
              "  'Team Retrospectives',\n",
              "  'project reporting',\n",
              "  'waterfall project management',\n",
              "  'research hypothesis formulation',\n",
              "  'project documentation',\n",
              "  'sampling methods',\n",
              "  'research reproducibility',\n",
              "  'quantitative methods',\n",
              "  'project scope management',\n",
              "  'project handover',\n",
              "  'ensemble methods',\n",
              "  'project planning',\n",
              "  'agile project management',\n",
              "  'project closure',\n",
              "  'llm research'],\n",
              " 'Big Data Technologies': ['Hadoop',\n",
              "  'Spark',\n",
              "  'Kafka',\n",
              "  'MapReduce',\n",
              "  'TensorFlow',\n",
              "  'Scikit-learn',\n",
              "  'Data Stream Processing',\n",
              "  'High-Performance Networks',\n",
              "  'Pig',\n",
              "  'Hive',\n",
              "  'Flume',\n",
              "  'HBase',\n",
              "  'Cassandra',\n",
              "  'Flink',\n",
              "  'Dask',\n",
              "  'NiFi',\n",
              "  'BigQuery',\n",
              "  'Dataflow',\n",
              "  'Storm',\n",
              "  'ElasticSearch',\n",
              "  'Snowflake',\n",
              "  'Redshift',\n",
              "  'Presto',\n",
              "  'Delta Lake',\n",
              "  'Vertica',\n",
              "  'Kudu',\n",
              "  'Mesos',\n",
              "  'Impala',\n",
              "  'Zookeeper',\n",
              "  'Bigtable',\n",
              "  'Oozie',\n",
              "  'Sqoop',\n",
              "  'AWS Glue',\n",
              "  'Google Data Studio',\n",
              "  'big data systems engineering'],\n",
              " 'Domain-Specific Knowledge': ['Healthcare Analytics',\n",
              "  'Finance Analytics',\n",
              "  'E-commerce Analytics',\n",
              "  'Government Data Systems',\n",
              "  'Open Data Utilization',\n",
              "  'IoT Analytics',\n",
              "  'Social Media Analytics',\n",
              "  'Marketing Analytics',\n",
              "  'Energy Analytics',\n",
              "  'Telecommunications Analytics',\n",
              "  'Retail Analytics',\n",
              "  'Supply Chain Analytics',\n",
              "  'Education Analytics',\n",
              "  'Transportation Analytics',\n",
              "  'Climate Data Analysis',\n",
              "  'Agriculture Analytics',\n",
              "  'Real Estate Analytics',\n",
              "  'Geospatial Data Analysis',\n",
              "  'Cybersecurity Analytics',\n",
              "  'Sports Analytics',\n",
              "  'Entertainment Analytics',\n",
              "  'Automotive Analytics',\n",
              "  'Travel Analytics',\n",
              "  'Manufacturing Analytics',\n",
              "  'Legal Analytics',\n",
              "  'Insurance Analytics',\n",
              "  'Gaming Analytics',\n",
              "  'Aviation Analytics',\n",
              "  'Military Data Analysis',\n",
              "  'Smart City Data Analysis',\n",
              "  'knowledge sharing',\n",
              "  'knowledge distillation',\n",
              "  'domain knowledge']}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the results of updated_reference_set\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "updated_reference_df = pd.DataFrame(list(updated_reference_set.items()), columns=['Category', 'Skills'])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "updated_reference_df.to_csv('updated_reference_set.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('updated_reference_set.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uYVENBMspa5w",
        "outputId": "77ed4c7f-96f8-41b6-dc83-85cfcd3f9755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cc724e3e-c9bb-4b8e-be6b-b3fd592d29a3\", \"updated_reference_set.csv\", 21906)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}